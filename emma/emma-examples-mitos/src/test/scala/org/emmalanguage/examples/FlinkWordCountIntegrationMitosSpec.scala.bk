/*
 * Copyright Â© 2014 TU Berlin (emma@dima.tu-berlin.de)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.emmalanguage
package examples

import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
import org.emmalanguage.api._
import org.emmalanguage.cli.mitosExamplesRunner.Config

//noinspection ScalaStyle
class FlinkWordCountIntegrationMitosSpec extends mitosAware {

  def wordCount(c: Config)(implicit flink: StreamExecutionEnvironment): Unit =
    emma.onmitos {
      // read the input files and split them into lowercased words
      val docs = DataBag.readText(c.input)
      // parse and count the words
      val words = for {
        line <- docs
        word <- DataBag[String](line.toLowerCase.split("\\W+"))
        if word != ""
      } yield word

      // group the words by their identity and count the occurrence of each word
      val counts = for {
        group <- words.groupBy(identity)
      } yield (group.key, group.values.size)
      // write the results into a file
      counts.writeCSV(c.output, c.csv)
    }


//  def rr() {
//    val registerCustomSerializer$m1 = _root_.org.emmalanguage.mitos.operators.LabyStatics.registerCustomSerializer();
//    val terminalBbId$m1 = _root_.org.emmalanguage.mitos.operators.LabyStatics.setTerminalBbid(0);
//    val kickOffSource$m1 = _root_.org.emmalanguage.mitos.operators.LabyStatics.setKickoffSource(0);
//    val fun$m6 = (() => {
//      val tmp$m1 = c.input;
//      tmp$m1
//    });
//    val fromNothing$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.fromNothing[_root_.java.lang.String](fun$m6);
//    val partitioner$m1 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.mitos.util.Nothing](1);
//    val typeInfo$m1 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m1 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m1);
//    val labyNode$m1 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.mitos.util.Nothing, _root_.java.lang.String]("fromNothing", fromNothing$m1, 0, partitioner$m1, null, elementOrEventTypeInfo$m1);
//    val setPrllzm$m1 = labyNode$m1.setParallelism(1);
//    val inputSplits$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.textSource;
//    val partitioner$m2 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.java.lang.String](1);
//    val typeInfo$m2 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.org.emmalanguage.mitos.operators.InputFormatWithInputSplit[_root_.java.lang.String, _root_.org.apache.flink.core.fs.FileInputSplit]];
//    val elementOrEventTypeInfo$m2 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.org.emmalanguage.mitos.operators.InputFormatWithInputSplit[_root_.java.lang.String, _root_.org.apache.flink.core.fs.FileInputSplit]](typeInfo$m2);
//    val labyNode$m2 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.java.lang.String, _root_.org.emmalanguage.mitos.operators.InputFormatWithInputSplit[_root_.java.lang.String, _root_.org.apache.flink.core.fs.FileInputSplit]]("inputSplits", inputSplits$m1, 0, partitioner$m2, null, elementOrEventTypeInfo$m2);
//    val addInput$m1 = labyNode$m2.addInput(setPrllzm$m1, true, false);
//    val setPrllzm$m2 = addInput$m1.setParallelism(1);
//    val readSplits$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.textReader;
//    val partitioner$m3 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.mitos.operators.InputFormatWithInputSplit[_root_.java.lang.String, _root_.org.apache.flink.core.fs.FileInputSplit]](1);
//    val typeInfo$m3 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m3 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m3);
//    val labyNode$m3 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.mitos.operators.InputFormatWithInputSplit[_root_.java.lang.String, _root_.org.apache.flink.core.fs.FileInputSplit], _root_.java.lang.String]("readSplits", readSplits$m1, 0, partitioner$m3, null, elementOrEventTypeInfo$m3);
//    val addInput$m2 = labyNode$m3.addInput(setPrllzm$m2, true, false);
//    val setPrllzm$m3 = addInput$m2.setParallelism(1);
//    val f$m1 = ((line$m1: _root_.java.lang.String) => {
//      val anf$m3 = line$m1.toLowerCase();
//      val anf$m4 = anf$m3.split("\\W+");
//      val anf$m5 = _root_.scala.Predef.wrapRefArray[_root_.java.lang.String](anf$m4);
//      val anf$m6 = _root_.org.emmalanguage.api.DataBag.apply[_root_.java.lang.String](anf$m5);
//      val p$m1 = ((word$m1: _root_.java.lang.String) => {
//        val anf$m7 = word$m1.!=("");
//        anf$m7
//      });
//      val filtered$m1 = anf$m6.withFilter(p$m1);
//      filtered$m1
//    });
//    val p$m1 = ((word$m1: _root_.java.lang.String) => {
//      val anf$m7 = word$m1.!=("");
//      anf$m7
//    });
//    val flatMapOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.flatMapDataBagHelper[_root_.java.lang.String, _root_.java.lang.String](f$m1);
//    val partitioner$m4 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.java.lang.String](1);
//    val typeInfo$m4 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m4 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m4);
//    val labyNode$m4 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.java.lang.String, _root_.java.lang.String]("flatMap", flatMapOp$m1, 0, partitioner$m4, null, elementOrEventTypeInfo$m4);
//    val addInput$m3 = labyNode$m4.addInput(setPrllzm$m3, true, false);
//    val setPrllzm$m4 = addInput$m3.setParallelism(1);
//    val f$m2 = ((word$m1: _root_.java.lang.String) => {
//      word$m1
//    });
//    val mapOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.map[_root_.java.lang.String, _root_.java.lang.String](f$m2);
//    val partitioner$m5 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.java.lang.String](1);
//    val typeInfo$m5 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m5 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m5);
//    val labyNode$m5 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.java.lang.String, _root_.java.lang.String]("map", mapOp$m1, 0, partitioner$m5, null, elementOrEventTypeInfo$m5);
//    val addInput$m4 = labyNode$m5.addInput(setPrllzm$m4, true, false);
//    val setPrllzm$m5 = addInput$m4.setParallelism(1);
//    val fun$m4 = ((x$m1: _root_.scala.Predef.String) => {
//      val anf$m11 = _root_.scala.Predef.identity[_root_.java.lang.String](x$m1);
//      anf$m11
//    });
//    val foldGroupOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.foldGroupAlgHelper[_root_.java.lang.String, _root_.java.lang.String, _root_.scala.Long](fun$m4, _root_.org.emmalanguage.api.alg.Size);
//    val partitioner$m6 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.java.lang.String](1);
//    val typeInfo$m6 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long]];
//    val elementOrEventTypeInfo$m6 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long]](typeInfo$m6);
//    val labyNode$m6 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.java.lang.String, _root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long]]("foldGroup", foldGroupOp$m1, 0, partitioner$m6, null, elementOrEventTypeInfo$m6);
//    val addInput$m5 = labyNode$m6.addInput(setPrllzm$m5, true, false);
//    val setPrllzm$m6 = addInput$m5.setParallelism(1);
//    val f$m3 = ((group$m1: _root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long]) => {
//      val anf$m13: group$m1.key.type = group$m1.key;
//      val anf$m15 = group$m1.values;
//      val anf$m16 = _root_.scala.Tuple2.apply[_root_.java.lang.String, _root_.scala.Long](anf$m13, anf$m15);
//      anf$m16
//    });
//    val mapOp$m2 = _root_.org.emmalanguage.mitos.operators.ScalaOps.map[_root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long], _root_.scala.Tuple2[_root_.java.lang.String, _root_.scala.Long]](f$m3);
//    val partitioner$m7 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long]](1);
//    val typeInfo$m7 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.scala.Tuple2[_root_.java.lang.String, _root_.scala.Long]];
//    val elementOrEventTypeInfo$m7 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.scala.Tuple2[_root_.java.lang.String, _root_.scala.Long]](typeInfo$m7);
//    val labyNode$m7 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.api.Group[_root_.java.lang.String, _root_.scala.Long], _root_.scala.Tuple2[_root_.java.lang.String, _root_.scala.Long]]("map", mapOp$m2, 0, partitioner$m7, null, elementOrEventTypeInfo$m7);
//    val addInput$m6 = labyNode$m7.addInput(setPrllzm$m6, true, false);
//    val setPrllzm$m7 = addInput$m6.setParallelism(1);
//    val fun$m7 = (() => {
//      val tmp$m2 = c.output;
//      tmp$m2
//    });
//    val fromNothing$m2 = _root_.org.emmalanguage.mitos.operators.ScalaOps.fromNothing[_root_.java.lang.String](fun$m7);
//    val partitioner$m8 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.mitos.util.Nothing](1);
//    val typeInfo$m8 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m8 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m8);
//    val labyNode$m8 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.mitos.util.Nothing, _root_.java.lang.String]("fromNothing", fromNothing$m2, 0, partitioner$m8, null, elementOrEventTypeInfo$m8);
//    val setPrllzm$m8 = labyNode$m8.setParallelism(1);
//    val fun$m8 = (() => {
//      val tmp$m3 = c.csv;
//      tmp$m3
//    });
//    val fromNothing$m3 = _root_.org.emmalanguage.mitos.operators.ScalaOps.fromNothing[_root_.org.emmalanguage.io.csv.CSV](fun$m8);
//    val partitioner$m9 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.mitos.util.Nothing](1);
//    val typeInfo$m9 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.org.emmalanguage.io.csv.CSV];
//    val elementOrEventTypeInfo$m9 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.org.emmalanguage.io.csv.CSV](typeInfo$m9);
//    val labyNode$m9 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.mitos.util.Nothing, _root_.org.emmalanguage.io.csv.CSV]("fromNothing", fromNothing$m3, 0, partitioner$m9, null, elementOrEventTypeInfo$m9);
//    val setPrllzm$m9 = labyNode$m9.setParallelism(1);
//    val toLeft$m1 = ((t$m1: _root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long]) => {
//      val lambda$m1 = _root_.scala.util.Left.apply[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.scala.Nothing](t$m1);
//      lambda$m1
//    });
//    val mapToLeftOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.map[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]](toLeft$m1);
//    val partitioner$m10 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long]](1);
//    val typeInfo$m10 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]];
//    val elementOrEventTypeInfo$m10 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]](typeInfo$m10);
//    val labyNode$m10 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]]("map", mapToLeftOp$m1, 0, partitioner$m10, null, elementOrEventTypeInfo$m10);
//    val addInput$m7 = labyNode$m10.addInput(setPrllzm$m7, true, false);
//    val setPrllzm$m10 = addInput$m7.setParallelism(1);
//    val toRight$m1 = ((t$m2: _root_.org.emmalanguage.io.csv.CSV) => {
//      val lambda$m2 = _root_.scala.util.Right.apply[_root_.scala.Nothing, _root_.org.emmalanguage.io.csv.CSV](t$m2);
//      lambda$m2
//    });
//    val mapToRightOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.map[_root_.org.emmalanguage.io.csv.CSV, _root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]](toRight$m1);
//    val partitioner$m11 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.org.emmalanguage.io.csv.CSV](1);
//    val typeInfo$m11 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]];
//    val elementOrEventTypeInfo$m11 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]](typeInfo$m11);
//    val labyNode$m11 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.org.emmalanguage.io.csv.CSV, _root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]]("map", mapToRightOp$m1, 0, partitioner$m11, null, elementOrEventTypeInfo$m11);
//    val addInput$m8 = labyNode$m11.addInput(setPrllzm$m9, true, false);
//    val setPrllzm$m11 = addInput$m8.setParallelism(1);
//    val toCsvStringOp$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.toCsvString[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long]];
//    val partitioner$m12 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV]](1);
//    val typeInfo$m12 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.java.lang.String];
//    val elementOrEventTypeInfo$m12 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.java.lang.String](typeInfo$m12);
//    val labyNode$m12 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.scala.util.Either[_root_.scala.Tuple2[_root_.scala.Predef.String, _root_.scala.Long], _root_.org.emmalanguage.io.csv.CSV], _root_.java.lang.String]("toCsvString", toCsvStringOp$m1, 0, partitioner$m12, null, elementOrEventTypeInfo$m12);
//    val addInput$m9 = labyNode$m12.addInput(setPrllzm$m10, true, false);
//    val addInput$m10 = addInput$m9.addInput(setPrllzm$m11, true, false);
//    val setPrllzm$m12 = addInput$m10.setParallelism(1);
//    val writeString$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.writeString;
//    val partitioner$m13 = new _root_.org.emmalanguage.mitos.partitioners.Always0[_root_.java.lang.String](1);
//    val typeInfo$m13 = _root_.org.emmalanguage.compiler.Memo.typeInfoForType[_root_.scala.Unit];
//    val elementOrEventTypeInfo$m13 = new _root_.org.emmalanguage.mitos.ElementOrEventTypeInfo[_root_.scala.Unit](typeInfo$m13);
//    val labyNode$m13 = new _root_.org.emmalanguage.mitos.LabyNode[_root_.java.lang.String, _root_.scala.Unit]("stringFileSink", writeString$m1, 0, partitioner$m13, null, elementOrEventTypeInfo$m13);
//    val addInput$m11 = labyNode$m13.addInput(setPrllzm$m8, true, false);
//    val addInput$m12 = addInput$m11.addInput(setPrllzm$m12, true, false);
//    val setPrllzm$m13 = addInput$m12.setParallelism(1);
//    val implEnv$m1 = _root_.scala.Predef.implicitly[_root_.org.apache.flink.streaming.api.scala.StreamExecutionEnvironment];
//    val socColl$m1 = _root_.org.emmalanguage.mitos.operators.ScalaOps.collectToClient[_root_.scala.Unit](implEnv$m1, setPrllzm$m13, 0);
//    val translateAll$m1 = _root_.org.emmalanguage.mitos.operators.LabyStatics.translateAll;
//    val `env.executeAndGetCollectedBag$m1` = _root_.org.emmalanguage.mitos.operators.LabyStatics.executeAndGetCollectedNonBag(implEnv$m1, socColl$m1);
//    `env.executeAndGetCollectedBag$m1`
//  }
}
